{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumanth718/ML-Project/blob/main/Project_Step1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0152ee5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0152ee5c",
        "outputId": "f008dd2e-bcca-483f-ca52-f0525d48d82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries loaded\n"
          ]
        }
      ],
      "source": [
        "## Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import os\n",
        "print('Libraries loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "08044ec8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "08044ec8",
        "outputId": "9cace912-041b-4075-84b1-f34593ad2711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files and directories in '/content/drive/MyDrive/':\n",
            "Colab Notebooks\n",
            "Priject_results\n",
            "UNSW.csv.csv\n",
            "IDS_project\n",
            "outputs\n",
            ".ipynb_checkpoints\n",
            "Lab6_results\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "\n",
        "print(f\"Listing files and directories in '{drive_path}':\")\n",
        "if os.path.exists(drive_path):\n",
        "    for item in os.listdir(drive_path):\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"Error: The path '{drive_path}' does not exist. Please ensure Google Drive is mounted correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "775ea071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "775ea071",
        "outputId": "56402de4-d9f2-46b4-dca6-bf1acba8f6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1487721004.py:12: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_unsw = pd.read_csv(unsw_file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSW.csv loaded into df_unsw successfully from Google Drive.\n",
            "DataFrame shape: (700000, 49)\n",
            "First 5 rows of df_unsw:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788  \\\n",
              "0  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
              "1  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
              "2  59.166.0.0   3804  149.171.126.3     53  udp  CON  0.000986   146    178   \n",
              "3  59.166.0.8  14339  149.171.126.6  14724  tcp  FIN  0.038480  8928    320   \n",
              "4  59.166.0.8  39094  149.171.126.3     53  udp  CON  0.001026   130    162   \n",
              "\n",
              "   31  ...  0.6  13  13.1  6  7.1  1  1.1  2  Unnamed: 47  0.7  \n",
              "0  31  ...    0  13    13  6    7  1    1  2          NaN    0  \n",
              "1  31  ...    1   1     2  7    5  1    1  4          NaN    0  \n",
              "2  31  ...    0  13    13  6    7  1    1  2          NaN    0  \n",
              "3  31  ...    0   8    20  7    5  1    1  4          NaN    0  \n",
              "4  31  ...    0   8    13  6    5  1    1  1          NaN    0  \n",
              "\n",
              "[5 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f14f967-a37e-4f10-b23b-7206599a20be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>59.166.0.0</th>\n",
              "      <th>6055</th>\n",
              "      <th>149.171.126.5</th>\n",
              "      <th>54145</th>\n",
              "      <th>tcp</th>\n",
              "      <th>FIN</th>\n",
              "      <th>0.072974</th>\n",
              "      <th>4238</th>\n",
              "      <th>60788</th>\n",
              "      <th>31</th>\n",
              "      <th>...</th>\n",
              "      <th>0.6</th>\n",
              "      <th>13</th>\n",
              "      <th>13.1</th>\n",
              "      <th>6</th>\n",
              "      <th>7.1</th>\n",
              "      <th>1</th>\n",
              "      <th>1.1</th>\n",
              "      <th>2</th>\n",
              "      <th>Unnamed: 47</th>\n",
              "      <th>0.7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>7832</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>5607</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>0.144951</td>\n",
              "      <td>5174</td>\n",
              "      <td>91072</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>11397</td>\n",
              "      <td>149.171.126.6</td>\n",
              "      <td>21</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>0.116107</td>\n",
              "      <td>2934</td>\n",
              "      <td>3742</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>3804</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>53</td>\n",
              "      <td>udp</td>\n",
              "      <td>CON</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>146</td>\n",
              "      <td>178</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>14339</td>\n",
              "      <td>149.171.126.6</td>\n",
              "      <td>14724</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>0.038480</td>\n",
              "      <td>8928</td>\n",
              "      <td>320</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>39094</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>53</td>\n",
              "      <td>udp</td>\n",
              "      <td>CON</td>\n",
              "      <td>0.001026</td>\n",
              "      <td>130</td>\n",
              "      <td>162</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f14f967-a37e-4f10-b23b-7206599a20be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f14f967-a37e-4f10-b23b-7206599a20be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f14f967-a37e-4f10-b23b-7206599a20be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9cf3023a-88d1-443b-b259-2e4997ccc8d7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cf3023a-88d1-443b-b259-2e4997ccc8d7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9cf3023a-88d1-443b-b259-2e4997ccc8d7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# IMPORTANT: Replace 'path/to/yohttps://colab.research.google.com/drive/1sx0oYxwyEGTekZ3FeZEc0uWbU5-82Meu#ur/UNSW.csv' with the actual path to your file in Google Drive.\n",
        "# For example: '/content/drive/MyDrive/UNSW.csv.csv' or '/content/drive/MyDrive/my_data/UNSW.csv.scv'\n",
        "unsw_file_path = '/content/drive/MyDrive/UNSW.csv.csv' # <--- CHANGE THIS PATH\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "try:\n",
        "    df_unsw = pd.read_csv(unsw_file_path)\n",
        "    print('UNSW.csv loaded into df_unsw successfully from Google Drive.')\n",
        "    print('DataFrame shape:', df_unsw.shape)\n",
        "    print('First 5 rows of df_unsw:')\n",
        "    display(df_unsw.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: '{unsw_file_path}' not found. Please ensure the file is uploaded to your Google Drive and the path is correct.\")\n",
        "    df_unsw = pd.DataFrame() # Create an empty DataFrame if file not found\n",
        "    print(\"An empty DataFrame 'df_unsw' has been created.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "    df_unsw = pd.DataFrame() # Create an empty DataFrame in case of other errors\n",
        "    print(\"An empty DataFrame 'df_unsw' has been created due to an error.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d31833",
      "metadata": {
        "id": "f0d31833"
      },
      "source": [
        "## III. Project — Step 1 (Scaffold)\n",
        "\n",
        "This section is a scaffold to help you complete the project tasks required by the lab:\n",
        "\n",
        "1. Descriptive analysis of your data.\n",
        "2. Implementation of necessary preprocessing.\n",
        "3. Formalisation of the problem.\n",
        "4. Selection of a baseline model and implementation.\n",
        "\n",
        "Fill this section with your dataset and details. Example code is provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2593ba0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2593ba0b",
        "outputId": "385b1323-fa0a-460e-effd-26af22efb447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project scaffold ready. Replace with your dataset and details.\n"
          ]
        }
      ],
      "source": [
        "def descriptive_analysis(df):\n",
        "    print('Shape:', df.shape)\n",
        "    display(df.head())\n",
        "    display(df.describe(include='all'))\n",
        "    print('\\nMissing values:\\n', df.isna().sum())\n",
        "\n",
        "# Example preprocessing\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Example baseline model building function\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def build_baseline_classifier(X, y):\n",
        "    # Simple baseline: StandardScaler + LogisticRegression\n",
        "    pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=500))])\n",
        "    pipe.fit(X, y)\n",
        "    return pipe\n",
        "\n",
        "print('Project scaffold ready. Replace with your dataset and details.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25bc0b29"
      },
      "source": [
        "# Task\n",
        "*   **Perform Descriptive Analysis**:\n",
        "    The `df_unsw` DataFrame is already loaded.\n",
        "*   **Formalize Machine Learning Problem**:\n",
        "    The features (X) and target variable (y) are already identified.\n",
        "*   **Preprocess Data**:\n",
        "    The data preprocessing steps, including handling mixed types, re-identifying numerical and categorical columns, and applying the `ColumnTransformer` to create `X_preprocessed`, have been completed.\n",
        "*   **Build and Evaluate Baseline Model**:\n",
        "    The Logistic Regression baseline model has been trained and evaluated using the preprocessed data.\n",
        "\n",
        "Based on the plan to re-execute these steps and then provide a comprehensive summary, I will regenerate the necessary code to display the descriptive analysis, problem formalization, preprocessing details, and baseline model performance. After that, I will provide the consolidated summary.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "# --- 1. Perform Descriptive Analysis ---\n",
        "print(\"--- 1. Descriptive Analysis of df_unsw ---\")\n",
        "print('Shape:', df_unsw.shape)\n",
        "print('First 5 rows of df_unsw:')\n",
        "display(df_unsw.head())\n",
        "print('\\nDescriptive statistics (all columns):')\n",
        "display(df_unsw.describe(include='all'))\n",
        "print('\\nMissing values:\\n', df_unsw.isna().sum())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- 2. Formalize Machine Learning Problem ---\n",
        "print(\"\\n--- 2. Machine Learning Problem Formalization ---\")\n",
        "print(\"The identified machine learning problem is a classification task.\")\n",
        "\n",
        "# Identify the target variable (y)\n",
        "y_column_name = df_unsw.columns[-1] # Assuming the last column is the target as per instruction\n",
        "y = df_unsw[y_column_name]\n",
        "\n",
        "# Create features (X) by dropping the target column\n",
        "X = df_unsw.drop(columns=[y_column_name])\n",
        "\n",
        "print(f\"\\nChosen target variable (y): '{y_column_name}'\")\n",
        "print(f\"Shape of features (X): {X.shape}\")\n",
        "print(f\"Shape of target (y): {y.shape}\")\n",
        "\n",
        "# Display unique values and their counts for y\n",
        "print(\"\\nUnique values and counts for the target variable (y):\")\n",
        "display(y.value_counts())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- 3. Preprocess Data ---\n",
        "print(\"\\n--- 3. Data Preprocessing ---\")\n",
        "\n",
        "# Handle mixed types by converting potentially numeric object columns to numeric\n",
        "potentially_numeric_object_cols = ['54145', '0.6', 'Unnamed: 47']\n",
        "for col in potentially_numeric_object_cols:\n",
        "    if col in X.columns and X[col].dtype == 'object':\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# Re-identify numerical and categorical columns after type conversion\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "print(f\"Updated Numerical columns ({len(numerical_cols)}):\\n{list(numerical_cols)}\")\n",
        "print(f\"\\nUpdated Categorical columns ({len(categorical_cols)}):\\n{list(categorical_cols)}\")\n",
        "\n",
        "# Preprocessing for numerical data: impute missing values with mean and then scale\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data: impute missing values with most frequent and then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Create a preprocessing pipeline\n",
        "preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "# Now fit and transform the data\n",
        "X_preprocessed = preprocessing_pipeline.fit_transform(X)\n",
        "\n",
        "print(f\"\\nOriginal features shape: {X.shape}\")\n",
        "print(f\"Preprocessed features shape: {X_preprocessed.shape}\")\n",
        "print(\"Data preprocessing complete. X_preprocessed contains the transformed features.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- 4. Build and Evaluate Baseline Model ---\n",
        "print(\"\\n--- 4. Baseline Model (Logistic Regression) Evaluation ---\")\n",
        "\n",
        "# Define the baseline model building function\n",
        "def build_baseline_classifier(X_transformed, y_target):\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs', multi_class='auto')\n",
        "    model.fit(X_transformed, y_target)\n",
        "    return model\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Build and train the baseline classifier\n",
        "baseline_model = build_baseline_classifier(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "print('\\nBaseline Model (Logistic Regression) Evaluation:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Baseline model implementation and evaluation complete.\")\n",
        "print(\"-\" * 50)\n",
        "```\n",
        "---\n",
        "## Comprehensive Summary of Initial Findings, Problem Formalization, and Baseline Model Performance\n",
        "\n",
        "This document summarizes the initial data analysis, formalization of the machine learning problem, and the performance of a baseline model on the `UNSW.csv` dataset.\n",
        "\n",
        "### 1. Data Analysis Key Findings\n",
        "\n",
        "*   **Dataset Shape**: The `df_unsw` dataset contains `700,000` rows and `49` columns.\n",
        "*   **Head of DataFrame**:\n",
        "    ```\n",
        "                59.166.0.0   6055  149.171.126.5  54145  tcp  ...   1  1.1   2  Unnamed: 47   0.7\n",
        "    0           59.166.0.0   7832  149.171.126.3   5607  tcp  ...   1    1   2          NaN     0\n",
        "    1           59.166.0.8  11397  149.171.126.6     21  tcp  ...   1    1   4          NaN     0\n",
        "    2           59.166.0.0   3804  149.171.126.3     53  udp  ...   1    1   2          NaN     0\n",
        "    3           59.166.0.8  14339  149.171.126.6  14724  tcp  ...   1    1   4          NaN     0\n",
        "    4           59.166.0.8  39094  149.171.126.3     53  udp  ...   1    1   1          NaN     0\n",
        "    ```\n",
        "*   **Missing Values**: Significant missing values were identified in three columns:\n",
        "    *   `0.4`: `285,256` missing values\n",
        "    *   `0.5`: `307,038` missing values\n",
        "    *   `Unnamed: 47`: `647,251` missing values (approximately 92% of the column)\n",
        "\n",
        "### 2. Problem Formalization\n",
        "\n",
        "*   **Problem Type**: The machine learning problem is formalized as a **binary classification task**.\n",
        "*   **Target Variable (y)**: The last column, named `'0.7'`, was chosen as the target variable.\n",
        "    *   Shape of target (y): `(700,000,)`\n",
        "*   **Features (X)**: All other `48` columns were designated as features.\n",
        "    *   Shape of features (X): `(700,000, 48)`\n",
        "*   **Target Variable Distribution**: The target variable exhibits significant class imbalance:\n",
        "    *   Class `0`: `647,251` instances\n",
        "    *   Class `1`: `52,749` instances\n",
        "\n",
        "### 3. Data Preprocessing\n",
        "\n",
        "*   **Mixed Type Handling**: Columns like `'54145'`, `'0.6'`, and `'Unnamed: 47'` were identified as potentially numeric but loaded as object types due to mixed data. These columns were explicitly converted to numeric, with errors coerced to `NaN`.\n",
        "*   **Column Re-identification**: After type conversion, the dataset was identified to have `43` numerical columns and `5` categorical columns.\n",
        "    *   Numerical columns: `['6055', '54145', '0.072974', '4238', '60788', '31', '29', '7', '30', '458245.4375', '6571546.5', '72', '72.1', '255', '255.1', '1003293149', '1003585034', '59', '844', '0', '0.1', '62.04531', '61.899776', '1421955842', '1421955842.1', '1.02269', '0.997042', '0.002317', '0.002173', '0.000144', '0.2', '0.3', '0.4', '0.5', '0.6', '13', '13.1', '6', '7.1', '1', '1.1', '2', 'Unnamed: 47']`\n",
        "    *   Categorical columns: `['59.166.0.0', '149.171.126.5', 'tcp', 'FIN', '-']`\n",
        "*   **Preprocessing Pipeline**: A `ColumnTransformer` was used within a `Pipeline`:\n",
        "    *   **Numerical Features**: Missing values were imputed with the mean, followed by `StandardScaler`.\n",
        "    *   **Categorical Features**: Missing values were imputed with the most frequent value, followed by `OneHotEncoder`.\n",
        "*   **Preprocessed Data Shape**: The original `(700,000, 48)` feature DataFrame `X` was transformed into `X_preprocessed` with shape `(700,000, 289)`.\n",
        "\n",
        "### 4. Baseline Model Performance\n",
        "\n",
        "*   **Model**: Logistic Regression (`max_iter=1000`, `solver='lbfgs'`).\n",
        "*   **Data Split**: The preprocessed data was split into training (`70%`) and testing (`30%`) sets, with stratification to maintain class distribution.\n",
        "    *   Training set shape: `X_train: (490000, 289)`, `y_train: (490000,)`\n",
        "    *   Testing set shape: `X_test: (210000, 289)`, `y_test: (210000,)`\n",
        "*   **Evaluation Metrics**:\n",
        "    *   **Accuracy**: `0.9928`\n",
        "    *   **Classification Report**:\n",
        "        ```\n",
        "                      precision    recall  f1-score   support\n",
        "\n",
        "               0       1.00      1.00      1.00    194175\n",
        "               1       0.94      0.96      0.95     15825\n",
        "\n",
        "            accuracy                           0.99    210000\n",
        "           macro avg       0.97      0.98      0.97    210000\n",
        "        weighted avg       0.99      0.99      0.99    210000\n",
        "        ```\n",
        "*   **Observations**:\n",
        "    *   The baseline Logistic Regression model achieved a very high overall accuracy of `0.9928`.\n",
        "    *   Performance for class `0` (majority class) is almost perfect across all metrics (precision, recall, f1-score of `1.00`).\n",
        "    *   Performance for class `1` (minority class) is also strong, with a precision of `0.94`, recall of `0.96`, and f1-score of `0.95`. This indicates that despite the class imbalance, the model is doing a reasonably good job of identifying the minority class.\n",
        "\n",
        "### Next Steps / Considerations\n",
        "\n",
        "*   **Class Imbalance**: While the current baseline performs well, the significant class imbalance should be kept in mind for more complex models, as it can sometimes lead to models that prioritize the majority class. Techniques like oversampling (SMOTE), undersampling, or using algorithms inherently robust to imbalance could be explored.\n",
        "*   **Feature Importance**: Investigating feature importance for the Logistic Regression model could provide insights into which features are most influential in predicting the target variable.\n",
        "*   **Further Model Exploration**: While the baseline is strong, exploring other classification algorithms (e.g., Decision Trees, Random Forests, Gradient Boosting) could lead to further performance improvements or provide a more robust model.\n",
        "*   **Hyperparameter Tuning**: Optimize the hyperparameters of the Logistic Regression model or other chosen models."
      ],
      "id": "25bc0b29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "248f383c"
      },
      "source": [
        "## Perform Descriptive Analysis\n",
        "\n",
        "### Subtask:\n",
        "Re-execute the descriptive analysis of the `df_unsw` DataFrame, including shape, head, descriptive statistics, and missing values count.\n"
      ],
      "id": "248f383c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac045812"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask explicitly asks to re-execute the descriptive analysis of the `df_unsw` DataFrame, which includes printing its shape, displaying the head, descriptive statistics, and missing value counts. The `descriptive_analysis` function previously defined in the notebook (and present in the current kernel state in cell `035f81e5`) performs all these actions. Therefore, calling this function on the `df_unsw` DataFrame will fulfill all requirements of the subtask.\n",
        "\n"
      ],
      "id": "ac045812"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1616
        },
        "id": "b9ac9e55",
        "outputId": "57caff25-bfad-4d44-d1f7-4af632630a5a"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "def descriptive_analysis(df):\n",
        "    print('Shape:', df.shape)\n",
        "    if df.empty:\n",
        "        print(\"DataFrame is empty, skipping detailed description and missing values check.\")\n",
        "        display(df.head())\n",
        "    else:\n",
        "        display(df.head())\n",
        "        display(df.describe(include='all'))\n",
        "        print('\\nMissing values:\\n', df.isna().sum())\n",
        "\n",
        "# Re-execute descriptive analysis on the df_unsw\n",
        "descriptive_analysis(df_unsw)"
      ],
      "id": "b9ac9e55",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (700000, 49)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788  \\\n",
              "0  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
              "1  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
              "2  59.166.0.0   3804  149.171.126.3     53  udp  CON  0.000986   146    178   \n",
              "3  59.166.0.8  14339  149.171.126.6  14724  tcp  FIN  0.038480  8928    320   \n",
              "4  59.166.0.8  39094  149.171.126.3     53  udp  CON  0.001026   130    162   \n",
              "\n",
              "   31  ...  0.6  13  13.1  6  7.1  1  1.1  2  Unnamed: 47  0.7  \n",
              "0  31  ...    0  13    13  6    7  1    1  2          NaN    0  \n",
              "1  31  ...    1   1     2  7    5  1    1  4          NaN    0  \n",
              "2  31  ...    0  13    13  6    7  1    1  2          NaN    0  \n",
              "3  31  ...    0   8    20  7    5  1    1  4          NaN    0  \n",
              "4  31  ...    0   8    13  6    5  1    1  1          NaN    0  \n",
              "\n",
              "[5 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-318f9ee6-4329-41b0-a9dd-cdb3b03934ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>59.166.0.0</th>\n",
              "      <th>6055</th>\n",
              "      <th>149.171.126.5</th>\n",
              "      <th>54145</th>\n",
              "      <th>tcp</th>\n",
              "      <th>FIN</th>\n",
              "      <th>0.072974</th>\n",
              "      <th>4238</th>\n",
              "      <th>60788</th>\n",
              "      <th>31</th>\n",
              "      <th>...</th>\n",
              "      <th>0.6</th>\n",
              "      <th>13</th>\n",
              "      <th>13.1</th>\n",
              "      <th>6</th>\n",
              "      <th>7.1</th>\n",
              "      <th>1</th>\n",
              "      <th>1.1</th>\n",
              "      <th>2</th>\n",
              "      <th>Unnamed: 47</th>\n",
              "      <th>0.7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>7832</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>5607</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>0.144951</td>\n",
              "      <td>5174</td>\n",
              "      <td>91072</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>11397</td>\n",
              "      <td>149.171.126.6</td>\n",
              "      <td>21</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>0.116107</td>\n",
              "      <td>2934</td>\n",
              "      <td>3742</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>3804</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>53</td>\n",
              "      <td>udp</td>\n",
              "      <td>CON</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>146</td>\n",
              "      <td>178</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>14339</td>\n",
              "      <td>149.171.126.6</td>\n",
              "      <td>14724</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>0.038480</td>\n",
              "      <td>8928</td>\n",
              "      <td>320</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>39094</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>53</td>\n",
              "      <td>udp</td>\n",
              "      <td>CON</td>\n",
              "      <td>0.001026</td>\n",
              "      <td>130</td>\n",
              "      <td>162</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-318f9ee6-4329-41b0-a9dd-cdb3b03934ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-318f9ee6-4329-41b0-a9dd-cdb3b03934ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-318f9ee6-4329-41b0-a9dd-cdb3b03934ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-494b96cc-4c75-458b-b662-702b614f22d6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-494b96cc-4c75-458b-b662-702b614f22d6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-494b96cc-4c75-458b-b662-702b614f22d6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        59.166.0.0           6055  149.171.126.5   54145     tcp     FIN  \\\n",
              "count       700000  700000.000000         700000  700000  700000  700000   \n",
              "unique          40            NaN             45  101736     134      15   \n",
              "top     59.166.0.0            NaN  149.171.126.2      53     tcp     FIN   \n",
              "freq         61811            NaN          61663   99207  455085  452052   \n",
              "mean           NaN   31330.022319            NaN     NaN     NaN     NaN   \n",
              "std            NaN   19896.179017            NaN     NaN     NaN     NaN   \n",
              "min            NaN       0.000000            NaN     NaN     NaN     NaN   \n",
              "25%            NaN   13498.000000            NaN     NaN     NaN     NaN   \n",
              "50%            NaN   31875.500000            NaN     NaN     NaN     NaN   \n",
              "75%            NaN   47455.000000            NaN     NaN     NaN     NaN   \n",
              "max            NaN   65535.000000            NaN     NaN     NaN     NaN   \n",
              "\n",
              "             0.072974          4238         60788             31  ...  \\\n",
              "count   700000.000000  7.000000e+05  7.000000e+05  700000.000000  ...   \n",
              "unique            NaN           NaN           NaN            NaN  ...   \n",
              "top               NaN           NaN           NaN            NaN  ...   \n",
              "freq              NaN           NaN           NaN            NaN  ...   \n",
              "mean         0.583991  4.439205e+03  3.821118e+04      49.803309  ...   \n",
              "std          3.117189  5.052684e+04  1.595661e+05      60.161503  ...   \n",
              "min          0.000000  0.000000e+00  0.000000e+00       0.000000  ...   \n",
              "25%          0.001120  2.640000e+02  1.780000e+02      31.000000  ...   \n",
              "50%          0.020339  1.580000e+03  2.456000e+03      31.000000  ...   \n",
              "75%          0.226749  3.598000e+03  1.629000e+04      31.000000  ...   \n",
              "max         59.999989  1.435577e+07  1.465753e+07     255.000000  ...   \n",
              "\n",
              "             0.6             13           13.1              6            7.1  \\\n",
              "count   700000.0  700000.000000  700000.000000  700000.000000  700000.000000   \n",
              "unique       9.0            NaN            NaN            NaN            NaN   \n",
              "top          0.0            NaN            NaN            NaN            NaN   \n",
              "freq    370147.0            NaN            NaN            NaN            NaN   \n",
              "mean         NaN       6.727760       6.549250       4.513316       5.035917   \n",
              "std          NaN       7.483271       7.438402       5.309101       5.489196   \n",
              "min          NaN       1.000000       1.000000       1.000000       1.000000   \n",
              "25%          NaN       2.000000       2.000000       2.000000       2.000000   \n",
              "50%          NaN       4.000000       4.000000       3.000000       4.000000   \n",
              "75%          NaN       8.000000       8.000000       5.000000       6.000000   \n",
              "max          NaN      63.000000      62.000000      60.000000      60.000000   \n",
              "\n",
              "                    1            1.1              2  Unnamed: 47  \\\n",
              "count   700000.000000  700000.000000  700000.000000        52749   \n",
              "unique            NaN            NaN            NaN            9   \n",
              "top               NaN            NaN            NaN      Generic   \n",
              "freq              NaN            NaN            NaN        27883   \n",
              "mean         2.609281       1.928206       4.062483          NaN   \n",
              "std          5.407286       3.862126       7.393228          NaN   \n",
              "min          1.000000       1.000000       1.000000          NaN   \n",
              "25%          1.000000       1.000000       1.000000          NaN   \n",
              "50%          1.000000       1.000000       2.000000          NaN   \n",
              "75%          1.000000       1.000000       3.000000          NaN   \n",
              "max         60.000000      60.000000      63.000000          NaN   \n",
              "\n",
              "                  0.7  \n",
              "count   700000.000000  \n",
              "unique            NaN  \n",
              "top               NaN  \n",
              "freq              NaN  \n",
              "mean         0.075356  \n",
              "std          0.263965  \n",
              "min          0.000000  \n",
              "25%          0.000000  \n",
              "50%          0.000000  \n",
              "75%          0.000000  \n",
              "max          1.000000  \n",
              "\n",
              "[11 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4e3de90-17f3-4ca8-acce-b01d0e44ef83\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>59.166.0.0</th>\n",
              "      <th>6055</th>\n",
              "      <th>149.171.126.5</th>\n",
              "      <th>54145</th>\n",
              "      <th>tcp</th>\n",
              "      <th>FIN</th>\n",
              "      <th>0.072974</th>\n",
              "      <th>4238</th>\n",
              "      <th>60788</th>\n",
              "      <th>31</th>\n",
              "      <th>...</th>\n",
              "      <th>0.6</th>\n",
              "      <th>13</th>\n",
              "      <th>13.1</th>\n",
              "      <th>6</th>\n",
              "      <th>7.1</th>\n",
              "      <th>1</th>\n",
              "      <th>1.1</th>\n",
              "      <th>2</th>\n",
              "      <th>Unnamed: 47</th>\n",
              "      <th>0.7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>700000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000</td>\n",
              "      <td>700000</td>\n",
              "      <td>700000</td>\n",
              "      <td>700000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>7.000000e+05</td>\n",
              "      <td>7.000000e+05</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>700000.0</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>700000.000000</td>\n",
              "      <td>52749</td>\n",
              "      <td>700000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45</td>\n",
              "      <td>101736</td>\n",
              "      <td>134</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>149.171.126.2</td>\n",
              "      <td>53</td>\n",
              "      <td>tcp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Generic</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>61811</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61663</td>\n",
              "      <td>99207</td>\n",
              "      <td>455085</td>\n",
              "      <td>452052</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>370147.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27883</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>31330.022319</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.583991</td>\n",
              "      <td>4.439205e+03</td>\n",
              "      <td>3.821118e+04</td>\n",
              "      <td>49.803309</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.727760</td>\n",
              "      <td>6.549250</td>\n",
              "      <td>4.513316</td>\n",
              "      <td>5.035917</td>\n",
              "      <td>2.609281</td>\n",
              "      <td>1.928206</td>\n",
              "      <td>4.062483</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.075356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>19896.179017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.117189</td>\n",
              "      <td>5.052684e+04</td>\n",
              "      <td>1.595661e+05</td>\n",
              "      <td>60.161503</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.483271</td>\n",
              "      <td>7.438402</td>\n",
              "      <td>5.309101</td>\n",
              "      <td>5.489196</td>\n",
              "      <td>5.407286</td>\n",
              "      <td>3.862126</td>\n",
              "      <td>7.393228</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.263965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>13498.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>2.640000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>31875.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.020339</td>\n",
              "      <td>1.580000e+03</td>\n",
              "      <td>2.456000e+03</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>47455.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.226749</td>\n",
              "      <td>3.598000e+03</td>\n",
              "      <td>1.629000e+04</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59.999989</td>\n",
              "      <td>1.435577e+07</td>\n",
              "      <td>1.465753e+07</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4e3de90-17f3-4ca8-acce-b01d0e44ef83')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4e3de90-17f3-4ca8-acce-b01d0e44ef83 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4e3de90-17f3-4ca8-acce-b01d0e44ef83');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8f644f25-2951-41fd-8b6a-3d5b135ef659\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f644f25-2951-41fd-8b6a-3d5b135ef659')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8f644f25-2951-41fd-8b6a-3d5b135ef659 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values:\n",
            " 59.166.0.0            0\n",
            "6055                  0\n",
            "149.171.126.5         0\n",
            "54145                 0\n",
            "tcp                   0\n",
            "FIN                   0\n",
            "0.072974              0\n",
            "4238                  0\n",
            "60788                 0\n",
            "31                    0\n",
            "29                    0\n",
            "7                     0\n",
            "30                    0\n",
            "-                     0\n",
            "458245.4375           0\n",
            "6571546.5             0\n",
            "72                    0\n",
            "72.1                  0\n",
            "255                   0\n",
            "255.1                 0\n",
            "1003293149            0\n",
            "1003585034            0\n",
            "59                    0\n",
            "844                   0\n",
            "0                     0\n",
            "0.1                   0\n",
            "62.04531              0\n",
            "61.899776             0\n",
            "1421955842            0\n",
            "1421955842.1          0\n",
            "1.02269               0\n",
            "0.997042              0\n",
            "0.002317              0\n",
            "0.002173              0\n",
            "0.000144              0\n",
            "0.2                   0\n",
            "0.3                   0\n",
            "0.4              285256\n",
            "0.5              307038\n",
            "0.6                   0\n",
            "13                    0\n",
            "13.1                  0\n",
            "6                     0\n",
            "7.1                   0\n",
            "1                     0\n",
            "1.1                   0\n",
            "2                     0\n",
            "Unnamed: 47      647251\n",
            "0.7                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95b1cacf"
      },
      "source": [
        "## Formalize Machine Learning Problem\n",
        "\n",
        "### Subtask:\n",
        "Re-execute the identification of features (X) and target variable (y) and display the target variable's class distribution.\n"
      ],
      "id": "95b1cacf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a81b20e"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires re-identifying the features (X) and target variable (y) and displaying the target variable's class distribution. I will regenerate the code to perform these steps, as requested in the instructions.\n",
        "\n"
      ],
      "id": "4a81b20e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "b6b57cdb",
        "outputId": "8706c778-5a1f-4afb-eb2d-a8c4add95008"
      },
      "source": [
        "print(\"The identified machine learning problem is a classification task.\")\n",
        "\n",
        "# Identify the target variable (y)\n",
        "y_column_name = df_unsw.columns[-1] # Assuming the last column is the target as per instruction\n",
        "y = df_unsw[y_column_name]\n",
        "\n",
        "# Create features (X) by dropping the target column\n",
        "X = df_unsw.drop(columns=[y_column_name])\n",
        "\n",
        "print(f\"\\nChosen target variable (y): '{y_column_name}'\")\n",
        "print(f\"Shape of features (X): {X.shape}\")\n",
        "print(f\"Shape of target (y): {y.shape}\")\n",
        "\n",
        "# Display unique values and their counts for y\n",
        "print(\"\\nUnique values and counts for the target variable (y):\")\n",
        "display(y.value_counts())"
      ],
      "id": "b6b57cdb",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The identified machine learning problem is a classification task.\n",
            "\n",
            "Chosen target variable (y): '0.7'\n",
            "Shape of features (X): (700000, 48)\n",
            "Shape of target (y): (700000,)\n",
            "\n",
            "Unique values and counts for the target variable (y):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.7\n",
              "0    647251\n",
              "1     52749\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.7</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>647251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52749</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "babb4bb4"
      },
      "source": [
        "## Preprocess Data\n",
        "\n",
        "### Subtask:\n",
        "Re-execute the data preprocessing steps, including handling mixed types, re-identifying numerical and categorical columns, and applying the ColumnTransformer to create X_preprocessed.\n"
      ],
      "id": "babb4bb4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cee37331"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires re-executing the data preprocessing steps, including handling mixed types, re-identifying column types, and applying a ColumnTransformer. The code will perform these actions sequentially, as specified in the instructions, to create the X_preprocessed DataFrame.\n",
        "\n"
      ],
      "id": "cee37331"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ce762e3f",
        "outputId": "55740918-1978-4a9d-9090-65ea93bec4a0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# --- 3. Data Preprocessing ---\n",
        "print(\"--- 3. Data Preprocessing ---\")\n",
        "\n",
        "# 1. Handle mixed types by converting potentially numeric object columns to numeric\n",
        "potentially_numeric_object_cols = ['54145', '0.6', 'Unnamed: 47'] # These were identified in previous run\n",
        "for col in potentially_numeric_object_cols:\n",
        "    if col in X.columns and X[col].dtype == 'object':\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# 2. Re-identify numerical and categorical columns after type conversion\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "print(f\"Updated Numerical columns ({len(numerical_cols)}):\\n{list(numerical_cols)}\")\n",
        "print(f\"\\nUpdated Categorical columns ({len(categorical_cols)}):\\n{list(categorical_cols)}\")\n",
        "\n",
        "# 3. Preprocessing for numerical data: impute missing values with mean and then scale\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 4. Preprocessing for categorical data: impute missing values with most frequent and then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# 5. Create a column transformer to apply different transformations to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# 6. Apply the ColumnTransformer to the features DataFrame X to create X_preprocessed\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# 7. Print the original features shape and the preprocessed features shape\n",
        "print(f\"\\nOriginal features shape: {X.shape}\")\n",
        "print(f\"Preprocessed features shape: {X_preprocessed.shape}\")\n",
        "print(\"Data preprocessing complete. X_preprocessed contains the transformed features.\")\n",
        "print(\"-\" * 50)"
      ],
      "id": "ce762e3f",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Data Preprocessing ---\n",
            "Updated Numerical columns (43):\n",
            "['6055', '54145', '0.072974', '4238', '60788', '31', '29', '7', '30', '458245.4375', '6571546.5', '72', '72.1', '255', '255.1', '1003293149', '1003585034', '59', '844', '0', '0.1', '62.04531', '61.899776', '1421955842', '1421955842.1', '1.02269', '0.997042', '0.002317', '0.002173', '0.000144', '0.2', '0.3', '0.4', '0.5', '0.6', '13', '13.1', '6', '7.1', '1', '1.1', '2', 'Unnamed: 47']\n",
            "\n",
            "Updated Categorical columns (5):\n",
            "['59.166.0.0', '149.171.126.5', 'tcp', 'FIN', '-']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Unnamed: 47']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original features shape: (700000, 48)\n",
            "Preprocessed features shape: (700000, 289)\n",
            "Data preprocessing complete. X_preprocessed contains the transformed features.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aec20f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous preprocessing step produced a UserWarning about 'Unnamed: 47' being skipped by SimpleImputer (mean strategy) due to having no observed values. To fix this warning and handle the highly sparse 'Unnamed: 47' column robustly, it will be processed separately with a constant imputation strategy (filling NaNs with 0) before scaling, while other numerical columns will retain their mean imputation.\n",
        "\n"
      ],
      "id": "17aec20f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "93a23bc3",
        "outputId": "9501f4d1-8234-480e-fd03-957b03b0ac2d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# --- 3. Data Preprocessing ---\n",
        "print(\"--- 3. Data Preprocessing ---\")\n",
        "\n",
        "# 1. Handle mixed types by converting potentially numeric object columns to numeric\n",
        "potentially_numeric_object_cols = ['54145', '0.6', 'Unnamed: 47']\n",
        "for col in potentially_numeric_object_cols:\n",
        "    if col in X.columns and X[col].dtype == 'object':\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# 2. Re-identify numerical and categorical columns after type conversion\n",
        "all_numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "# Separate 'Unnamed: 47' for specific imputation\n",
        "numerical_cols_for_mean_imputation = [col for col in all_numerical_cols if col != 'Unnamed: 47']\n",
        "unnamed_47_col = ['Unnamed: 47'] if 'Unnamed: 47' in all_numerical_cols else []\n",
        "\n",
        "print(f\"Numerical columns for mean imputation ({len(numerical_cols_for_mean_imputation)}):\\n{list(numerical_cols_for_mean_imputation)}\")\n",
        "print(f\"Specific numerical columns for constant imputation ({len(unnamed_47_col)}):\\n{list(unnamed_47_col)}\")\n",
        "print(f\"\\nCategorical columns ({len(categorical_cols)}):\\n{list(categorical_cols)}\")\n",
        "\n",
        "transformers = []\n",
        "\n",
        "# Preprocessing for numerical data (mean imputation and scaling)\n",
        "if len(numerical_cols_for_mean_imputation) > 0:\n",
        "    numerical_transformer_mean = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_mean', numerical_transformer_mean, numerical_cols_for_mean_imputation))\n",
        "\n",
        "# Preprocessing for 'Unnamed: 47' (constant imputation and scaling)\n",
        "if len(unnamed_47_col) > 0:\n",
        "    numerical_transformer_constant = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)), # Address the warning by using constant imputation\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_constant', numerical_transformer_constant, unnamed_47_col))\n",
        "\n",
        "# Preprocessing for categorical data: impute missing values with most frequent and then one-hot encode\n",
        "if len(categorical_cols) > 0:\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "    transformers.append(('cat', categorical_transformer, categorical_cols))\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "# Default remainder is 'drop', which is fine as all relevant columns are handled.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=transformers\n",
        ")\n",
        "\n",
        "# Apply the ColumnTransformer to the features DataFrame X to create X_preprocessed\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Print the original features shape and the preprocessed features shape\n",
        "print(f\"\\nOriginal features shape: {X.shape}\")\n",
        "print(f\"Preprocessed features shape: {X_preprocessed.shape}\")\n",
        "print(\"Data preprocessing complete. X_preprocessed contains the transformed features.\")\n",
        "print(\"-\" * 50)"
      ],
      "id": "93a23bc3",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Data Preprocessing ---\n",
            "Numerical columns for mean imputation (42):\n",
            "['6055', '54145', '0.072974', '4238', '60788', '31', '29', '7', '30', '458245.4375', '6571546.5', '72', '72.1', '255', '255.1', '1003293149', '1003585034', '59', '844', '0', '0.1', '62.04531', '61.899776', '1421955842', '1421955842.1', '1.02269', '0.997042', '0.002317', '0.002173', '0.000144', '0.2', '0.3', '0.4', '0.5', '0.6', '13', '13.1', '6', '7.1', '1', '1.1', '2']\n",
            "Specific numerical columns for constant imputation (1):\n",
            "['Unnamed: 47']\n",
            "\n",
            "Categorical columns (5):\n",
            "['59.166.0.0', '149.171.126.5', 'tcp', 'FIN', '-']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:572: FutureWarning: Currently, when `keep_empty_feature=False` and `strategy=\"constant\"`, empty features are not dropped. This behaviour will change in version 1.8. Set `keep_empty_feature=True` to preserve this behaviour.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original features shape: (700000, 48)\n",
            "Preprocessed features shape: (700000, 290)\n",
            "Data preprocessing complete. X_preprocessed contains the transformed features.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28e25a6a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step raised a FutureWarning related to SimpleImputer with `strategy='constant'` and `keep_empty_feature=False`. To suppress this warning and ensure consistent behavior with future scikit-learn versions, the `SimpleImputer` for `unnamed_47_col` will be explicitly updated to set `keep_empty_feature=True`.\n",
        "\n"
      ],
      "id": "28e25a6a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7afa8a90",
        "outputId": "12ce3173-7aaf-45d4-f5f3-51867a9747bf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# --- 3. Data Preprocessing ---\n",
        "print(\"--- 3. Data Preprocessing ---\")\n",
        "\n",
        "# 1. Handle mixed types by converting potentially numeric object columns to numeric\n",
        "potentially_numeric_object_cols = ['54145', '0.6', 'Unnamed: 47']\n",
        "for col in potentially_numeric_object_cols:\n",
        "    if col in X.columns and X[col].dtype == 'object':\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# 2. Re-identify numerical and categorical columns after type conversion\n",
        "all_numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "# Separate 'Unnamed: 47' for specific imputation\n",
        "numerical_cols_for_mean_imputation = [col for col in all_numerical_cols if col != 'Unnamed: 47']\n",
        "unnamed_47_col = ['Unnamed: 47'] if 'Unnamed: 47' in all_numerical_cols else []\n",
        "\n",
        "print(f\"Numerical columns for mean imputation ({len(numerical_cols_for_mean_imputation)}):\\n{list(numerical_cols_for_mean_imputation)}\")\n",
        "print(f\"Specific numerical columns for constant imputation ({len(unnamed_47_col)}):\\n{list(unnamed_47_col)}\")\n",
        "print(f\"\\nCategorical columns ({len(categorical_cols)}):\\n{list(categorical_cols)}\")\n",
        "\n",
        "transformers = []\n",
        "\n",
        "# Preprocessing for numerical data (mean imputation and scaling)\n",
        "if len(numerical_cols_for_mean_imputation) > 0:\n",
        "    numerical_transformer_mean = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_mean', numerical_transformer_mean, numerical_cols_for_mean_imputation))\n",
        "\n",
        "# Preprocessing for 'Unnamed: 47' (constant imputation and scaling)\n",
        "if len(unnamed_47_col) > 0:\n",
        "    numerical_transformer_constant = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)), # Removed keep_empty_feature=True\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_constant', numerical_transformer_constant, unnamed_47_col))\n",
        "\n",
        "# Preprocessing for categorical data: impute missing values with most frequent and then one-hot encode\n",
        "if len(categorical_cols) > 0:\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "    transformers.append(('cat', categorical_transformer, categorical_cols))\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "# Default remainder is 'drop', which is fine as all relevant columns are handled.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=transformers\n",
        ")\n",
        "\n",
        "# Apply the ColumnTransformer to the features DataFrame X to create X_preprocessed\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Print the original features shape and the preprocessed features shape\n",
        "print(f\"\\nOriginal features shape: {X.shape}\")\n",
        "print(f\"Preprocessed features shape: {X_preprocessed.shape}\")\n",
        "print(\"Data preprocessing complete. X_preprocessed contains the transformed features.\")\n",
        "print(\"-\" * 50)\n"
      ],
      "id": "7afa8a90",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Data Preprocessing ---\n",
            "Numerical columns for mean imputation (42):\n",
            "['6055', '54145', '0.072974', '4238', '60788', '31', '29', '7', '30', '458245.4375', '6571546.5', '72', '72.1', '255', '255.1', '1003293149', '1003585034', '59', '844', '0', '0.1', '62.04531', '61.899776', '1421955842', '1421955842.1', '1.02269', '0.997042', '0.002317', '0.002173', '0.000144', '0.2', '0.3', '0.4', '0.5', '0.6', '13', '13.1', '6', '7.1', '1', '1.1', '2']\n",
            "Specific numerical columns for constant imputation (1):\n",
            "['Unnamed: 47']\n",
            "\n",
            "Categorical columns (5):\n",
            "['59.166.0.0', '149.171.126.5', 'tcp', 'FIN', '-']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:572: FutureWarning: Currently, when `keep_empty_feature=False` and `strategy=\"constant\"`, empty features are not dropped. This behaviour will change in version 1.8. Set `keep_empty_feature=True` to preserve this behaviour.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original features shape: (700000, 48)\n",
            "Preprocessed features shape: (700000, 290)\n",
            "Data preprocessing complete. X_preprocessed contains the transformed features.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75eea94a"
      },
      "source": [
        "**Reasoning**:\n",
        "The `TypeError` indicates that the `keep_empty_feature` argument is not supported by the version of `SimpleImputer` in this environment. I need to remove this argument to resolve the error and allow the preprocessing to proceed.\n",
        "\n"
      ],
      "id": "75eea94a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2abeab"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# --- 3. Data Preprocessing ---\n",
        "print(\"--- 3. Data Preprocessing ---\")\n",
        "\n",
        "# 1. Handle mixed types by converting potentially numeric object columns to numeric\n",
        "potentially_numeric_object_cols = ['54145', '0.6', 'Unnamed: 47']\n",
        "for col in potentially_numeric_object_cols:\n",
        "    if col in X.columns and X[col].dtype == 'object':\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# 2. Re-identify numerical and categorical columns after type conversion\n",
        "all_numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "# Separate 'Unnamed: 47' for specific imputation\n",
        "numerical_cols_for_mean_imputation = [col for col in all_numerical_cols if col != 'Unnamed: 47']\n",
        "unnamed_47_col = ['Unnamed: 47'] if 'Unnamed: 47' in all_numerical_cols else []\n",
        "\n",
        "print(f\"Numerical columns for mean imputation ({len(numerical_cols_for_mean_imputation)}):\\n{list(numerical_cols_for_mean_imputation)}\")\n",
        "print(f\"Specific numerical columns for constant imputation ({len(unnamed_47_col)}):\\n{list(unnamed_47_col)}\")\n",
        "print(f\"\\nCategorical columns ({len(categorical_cols)}):\\n{list(categorical_cols)}\")\n",
        "\n",
        "transformers = []\n",
        "\n",
        "# Preprocessing for numerical data (mean imputation and scaling)\n",
        "if len(numerical_cols_for_mean_imputation) > 0:\n",
        "    numerical_transformer_mean = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_mean', numerical_transformer_mean, numerical_cols_for_mean_imputation))\n",
        "\n",
        "# Preprocessing for 'Unnamed: 47' (constant imputation and scaling)\n",
        "if len(unnamed_47_col) > 0:\n",
        "    numerical_transformer_constant = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)), # Removed keep_empty_feature=True\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_constant', numerical_transformer_constant, unnamed_47_col))\n",
        "\n",
        "# Preprocessing for categorical data: impute missing values with most frequent and then one-hot encode\n",
        "if len(categorical_cols) > 0:\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "    transformers.append(('cat', categorical_transformer, categorical_cols))\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "# Default remainder is 'drop', which is fine as all relevant columns are handled.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=transformers\n",
        ")\n",
        "\n",
        "# Apply the ColumnTransformer to the features DataFrame X to create X_preprocessed\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Print the original features shape and the preprocessed features shape\n",
        "print(f\"\\nOriginal features shape: {X.shape}\")\n",
        "print(f\"Preprocessed features shape: {X_preprocessed.shape}\")\n",
        "print(\"Data preprocessing complete. X_preprocessed contains the transformed features.\")\n",
        "print(\"-\" * 50)"
      ],
      "id": "5a2abeab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9525f199"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code already correctly removes the unsupported `keep_empty_feature` argument from `SimpleImputer`, which resolved the `TypeError`. This code successfully processes the data, and while it produces a `FutureWarning`, it does not block execution or indicate incorrect behavior for the current scikit-learn version.\n",
        "\n"
      ],
      "id": "9525f199"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "132084d6",
        "outputId": "7922cd15-1248-41aa-b3e7-6e46b5f41f7c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# --- 3. Data Preprocessing ---\n",
        "print(\"--- 3. Data Preprocessing ---\")\n",
        "\n",
        "# 1. Handle mixed types by converting potentially numeric object columns to numeric\n",
        "potentially_numeric_object_cols = ['54145', '0.6', 'Unnamed: 47']\n",
        "for col in potentially_numeric_object_cols:\n",
        "    if col in X.columns and X[col].dtype == 'object':\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# 2. Re-identify numerical and categorical columns after type conversion\n",
        "all_numerical_cols = X.select_dtypes(include=np.number).columns\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "# Separate 'Unnamed: 47' for specific imputation\n",
        "numerical_cols_for_mean_imputation = [col for col in all_numerical_cols if col != 'Unnamed: 47']\n",
        "unnamed_47_col = ['Unnamed: 47'] if 'Unnamed: 47' in all_numerical_cols else []\n",
        "\n",
        "print(f\"Numerical columns for mean imputation ({len(numerical_cols_for_mean_imputation)}):\\n{list(numerical_cols_for_mean_imputation)}\")\n",
        "print(f\"Specific numerical columns for constant imputation ({len(unnamed_47_col)}):\\n{list(unnamed_47_col)}\")\n",
        "print(f\"\\nCategorical columns ({len(categorical_cols)}):\\n{list(categorical_cols)}\")\n",
        "\n",
        "transformers = []\n",
        "\n",
        "# Preprocessing for numerical data (mean imputation and scaling)\n",
        "if len(numerical_cols_for_mean_imputation) > 0:\n",
        "    numerical_transformer_mean = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_mean', numerical_transformer_mean, numerical_cols_for_mean_imputation))\n",
        "\n",
        "# Preprocessing for 'Unnamed: 47' (constant imputation and scaling)\n",
        "if len(unnamed_47_col) > 0:\n",
        "    numerical_transformer_constant = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    transformers.append(('num_constant', numerical_transformer_constant, unnamed_47_col))\n",
        "\n",
        "# Preprocessing for categorical data: impute missing values with most frequent and then one-hot encode\n",
        "if len(categorical_cols) > 0:\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "    transformers.append(('cat', categorical_transformer, categorical_cols))\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "# Default remainder is 'drop', which is fine as all relevant columns are handled.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=transformers\n",
        ")\n",
        "\n",
        "# Apply the ColumnTransformer to the features DataFrame X to create X_preprocessed\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Print the original features shape and the preprocessed features shape\n",
        "print(f\"\\nOriginal features shape: {X.shape}\")\n",
        "print(f\"Preprocessed features shape: {X_preprocessed.shape}\")\n",
        "print(\"Data preprocessing complete. X_preprocessed contains the transformed features.\")\n",
        "print(\"-\" * 50)\n"
      ],
      "id": "132084d6",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Data Preprocessing ---\n",
            "Numerical columns for mean imputation (42):\n",
            "['6055', '54145', '0.072974', '4238', '60788', '31', '29', '7', '30', '458245.4375', '6571546.5', '72', '72.1', '255', '255.1', '1003293149', '1003585034', '59', '844', '0', '0.1', '62.04531', '61.899776', '1421955842', '1421955842.1', '1.02269', '0.997042', '0.002317', '0.002173', '0.000144', '0.2', '0.3', '0.4', '0.5', '0.6', '13', '13.1', '6', '7.1', '1', '1.1', '2']\n",
            "Specific numerical columns for constant imputation (1):\n",
            "['Unnamed: 47']\n",
            "\n",
            "Categorical columns (5):\n",
            "['59.166.0.0', '149.171.126.5', 'tcp', 'FIN', '-']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:572: FutureWarning: Currently, when `keep_empty_feature=False` and `strategy=\"constant\"`, empty features are not dropped. This behaviour will change in version 1.8. Set `keep_empty_feature=True` to preserve this behaviour.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original features shape: (700000, 48)\n",
            "Preprocessed features shape: (700000, 290)\n",
            "Data preprocessing complete. X_preprocessed contains the transformed features.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2c71620"
      },
      "source": [
        "**Reasoning**:\n",
        "The data preprocessing step has been successfully completed, resulting in `X_preprocessed`. The next logical step, as per the overall project plan, is to re-execute the building and evaluation of the baseline model using this preprocessed data. This involves splitting the data into training and testing sets, training a Logistic Regression model, and then evaluating its performance using accuracy and a classification report.\n",
        "\n"
      ],
      "id": "a2c71620"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c503ab8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# --- 4. Build and Evaluate Baseline Model ---\n",
        "print(\"\\n--- 4. Baseline Model (Logistic Regression) Evaluation ---\")\n",
        "\n",
        "# Define the baseline model building function\n",
        "def build_baseline_classifier(X_transformed, y_target):\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs', multi_class='auto')\n",
        "    model.fit(X_transformed, y_target)\n",
        "    return model\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "# Ensure y is a Series/DataFrame if it's not already, for stratification\n",
        "if isinstance(y, (pd.Series, pd.DataFrame)):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42, stratify=y)\n",
        "else:\n",
        "    # Fallback if y is a numpy array, stratification might need adjustment for multi-class\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Build and train the baseline classifier\n",
        "baseline_model = build_baseline_classifier(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "print('\\nBaseline Model (Logistic Regression) Evaluation:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Baseline model implementation and evaluation complete.\")\n",
        "print(\"-\" * 50)\n"
      ],
      "id": "8c503ab8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3cc4601"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step produced a `FutureWarning` regarding the `multi_class` parameter in `LogisticRegression`, indicating it will be deprecated. To remove this warning and ensure forward compatibility, I will remove the `multi_class='auto'` argument from the `LogisticRegression` constructor, allowing it to use its default behavior.\n",
        "\n"
      ],
      "id": "c3cc4601"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d0dfca4f",
        "outputId": "37d37d73-8a5a-41ca-ef46-d444498ffffd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# --- 4. Build and Evaluate Baseline Model ---\n",
        "print(\"\\n--- 4. Baseline Model (Logistic Regression) Evaluation ---\")\n",
        "\n",
        "# Define the baseline model building function\n",
        "def build_baseline_classifier(X_transformed, y_target):\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs') # Removed multi_class='auto'\n",
        "    model.fit(X_transformed, y_target)\n",
        "    return model\n",
        "\n",
        "# Split the preprocessed data into training and testing sets\n",
        "# Ensure y is a Series/DataFrame if it's not already, for stratification\n",
        "if isinstance(y, (pd.Series, pd.DataFrame)):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42, stratify=y)\n",
        "else:\n",
        "    # Fallback if y is a numpy array, stratification might need adjustment for multi-class\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Build and train the baseline classifier\n",
        "baseline_model = build_baseline_classifier(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "print('\\nBaseline Model (Logistic Regression) Evaluation:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Baseline model implementation and evaluation complete.\")\n",
        "print(\"-\" * 50)\n"
      ],
      "id": "d0dfca4f",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Baseline Model (Logistic Regression) Evaluation ---\n",
            "Training set shape: (490000, 290), (490000,)\n",
            "Testing set shape: (210000, 290), (210000,)\n",
            "\n",
            "Baseline Model (Logistic Regression) Evaluation:\n",
            "Accuracy: 0.9929\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    194175\n",
            "           1       0.95      0.96      0.95     15825\n",
            "\n",
            "    accuracy                           0.99    210000\n",
            "   macro avg       0.97      0.98      0.97    210000\n",
            "weighted avg       0.99      0.99      0.99    210000\n",
            "\n",
            "Baseline model implementation and evaluation complete.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "080e62da"
      },
      "source": [
        "# Task\n",
        "## Implement Ensemble Model (RandomForest)\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a RandomForestClassifier. Evaluate its baseline performance using accuracy and a classification report on the test set."
      ],
      "id": "080e62da"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f509bd5"
      },
      "source": [
        "## Implement Ensemble Model (RandomForest)\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train a RandomForestClassifier. Evaluate its baseline performance using accuracy and a classification report on the test set.\n"
      ],
      "id": "2f509bd5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4168ad32"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires initializing, training, and evaluating a RandomForestClassifier model. This code block will import the necessary class, create an instance, train it with the preprocessed data, make predictions, and then print the accuracy score and classification report.\n",
        "\n"
      ],
      "id": "4168ad32"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e2fc2c57",
        "outputId": "a1435b60-ba17-4d83-ec45-7338b12dfb30"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"\\n--- Implementing Ensemble Model (RandomForest) ---\")\n",
        "\n",
        "# 1. Initialize a RandomForestClassifier object\n",
        "# Set random_state for reproducibility and n_estimators as a starting point\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 to use all available cores\n",
        "\n",
        "# 2. Train the RandomForestClassifier model\n",
        "print(\"Training RandomForestClassifier...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"RandomForestClassifier training complete.\")\n",
        "\n",
        "# 3. Make predictions on the test features\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# 4. Evaluate the model\n",
        "print('\\nRandomForestClassifier Evaluation:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"--------------------------------------------------\")"
      ],
      "id": "e2fc2c57",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Implementing Ensemble Model (RandomForest) ---\n",
            "Training RandomForestClassifier...\n",
            "RandomForestClassifier training complete.\n",
            "\n",
            "RandomForestClassifier Evaluation:\n",
            "Accuracy: 0.9973\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    194175\n",
            "           1       0.98      0.98      0.98     15825\n",
            "\n",
            "    accuracy                           1.00    210000\n",
            "   macro avg       0.99      0.99      0.99    210000\n",
            "weighted avg       1.00      1.00      1.00    210000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1229fb"
      },
      "source": [
        "## Define Parameter Grid for Grid Search\n",
        "\n",
        "### Subtask:\n",
        "Define a dictionary of hyperparameters for the RandomForestClassifier that will be tuned using Grid Search. Include parameters like `n_estimators`, `max_depth`, and `min_samples_leaf`.\n"
      ],
      "id": "de1229fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1323c992"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining a dictionary of hyperparameters for the RandomForestClassifier to be used in Grid Search, as specified in the instructions. This dictionary will be named `param_grid` and will include `n_estimators`, `max_depth`, and `min_samples_leaf`.\n",
        "\n"
      ],
      "id": "1323c992"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "04732d52",
        "outputId": "03238a90-82df-477e-ba55-9212ef5738a8"
      },
      "source": [
        "print(\"--- Defining Parameter Grid for Grid Search ---\")\n",
        "\n",
        "# Define the parameter grid for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
        "    'max_depth': [10, 20, None],   # Maximum depth of the tree (None means unlimited)\n",
        "    'min_samples_leaf': [1, 5, 10] # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "print(\"Parameter grid defined successfully:\")\n",
        "for param, values in param_grid.items():\n",
        "    print(f\"  {param}: {values}\")\n",
        "print(\"--------------------------------------------------\")"
      ],
      "id": "04732d52",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining Parameter Grid for Grid Search ---\n",
            "Parameter grid defined successfully:\n",
            "  n_estimators: [50, 100, 200]\n",
            "  max_depth: [10, 20, None]\n",
            "  min_samples_leaf: [1, 5, 10]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbee4d63"
      },
      "source": [
        "## Perform Grid Search on Ensemble Model\n",
        "\n",
        "### Subtask:\n",
        "Apply GridSearchCV to the RandomForestClassifier using the defined parameter grid. This step will systematically search for the best combination of hyperparameters that maximize model performance (e.g., accuracy or F1-score).\n"
      ],
      "id": "dbee4d63"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d03a81b"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires applying GridSearchCV to the RandomForestClassifier using the previously defined parameter grid. This involves importing `GridSearchCV`, initializing it with the model and parameters, fitting it to the training data, and then printing the best parameters and score found.\n",
        "\n"
      ],
      "id": "2d03a81b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bf2d3220",
        "outputId": "db89f1a8-e016-4afb-8f23-6d9e50fab074"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"--- Applying GridSearchCV to RandomForestClassifier ---\")\n",
        "\n",
        "# 1. Initialize GridSearchCV\n",
        "# Using cv=3 for quicker execution, and 'accuracy' as the scoring metric.\n",
        "# n_jobs=-1 to utilize all available cores for parallel processing.\n",
        "grid_search = GridSearchCV(estimator=rf_model,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3, # Using 3-fold cross-validation\n",
        "                           scoring='accuracy', # Or 'f1_weighted', 'roc_auc' depending on problem\n",
        "                           verbose=2, # Increased verbosity to see progress\n",
        "                           n_jobs=-1) # Use all available cores\n",
        "\n",
        "# 2. Fit GridSearchCV to the training data\n",
        "print(\"Fitting GridSearchCV...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"GridSearchCV fitting complete.\")\n",
        "\n",
        "# 3. Print the best parameters found\n",
        "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "# 4. Print the best score obtained\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
        "print(\"--------------------------------------------------\")"
      ],
      "id": "bf2d3220",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Applying GridSearchCV to RandomForestClassifier ---\n",
            "Fitting GridSearchCV...\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "GridSearchCV fitting complete.\n",
            "\n",
            "Best parameters found: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
            "Best cross-validation accuracy: 0.9970\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3478caa1"
      },
      "source": [
        "## Evaluate Best Ensemble Model from Grid Search\n",
        "\n",
        "### Subtask:\n",
        "Retrieve the best estimator from the Grid Search results and evaluate its performance on the test set using accuracy and a classification report. Compare these results with the initial baseline ensemble model.\n"
      ],
      "id": "3478caa1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "561bb011"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires retrieving the best estimator from the completed GridSearchCV, using it to make predictions on the test set, and then evaluating its performance using accuracy and a classification report.\n",
        "\n"
      ],
      "id": "561bb011"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "429a04e0",
        "outputId": "3231acc0-a13c-45e1-a584-e2ef582d205f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"--- Evaluating Best Ensemble Model from Grid Search ---\")\n",
        "\n",
        "# 1. Retrieve the best performing model from GridSearchCV\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(f\"Best RandomForest model found: {best_rf_model}\")\n",
        "\n",
        "# 2. Use the best_rf_model to make predictions on the test set\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# 3. Calculate and print the accuracy score\n",
        "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
        "print(f'\\nBest RandomForest Model (from Grid Search) Evaluation:')\n",
        "print(f'Accuracy: {accuracy_best_rf:.4f}')\n",
        "\n",
        "# 4. Generate and print a classification report\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred_best_rf))\n",
        "print(\"--------------------------------------------------\")"
      ],
      "id": "429a04e0",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating Best Ensemble Model from Grid Search ---\n",
            "Best RandomForest model found: RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n",
            "\n",
            "Best RandomForest Model (from Grid Search) Evaluation:\n",
            "Accuracy: 0.9974\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    194175\n",
            "           1       0.98      0.98      0.98     15825\n",
            "\n",
            "    accuracy                           1.00    210000\n",
            "   macro avg       0.99      0.99      0.99    210000\n",
            "weighted avg       1.00      1.00      1.00    210000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1996f7"
      },
      "source": [
        "### Comparison with Baseline Ensemble Model\n",
        "\n",
        "**Initial RandomForestClassifier Performance (Baseline):**\n",
        "*   **Accuracy**: `0.9973`\n",
        "*   **Class 0 (Majority)**: Precision: `1.00`, Recall: `1.00`, F1-score: `1.00`\n",
        "*   **Class 1 (Minority)**: Precision: `0.98`, Recall: `0.98`, F1-score: `0.98`\n",
        "\n",
        "**Best RandomForestClassifier Performance (from Grid Search):**\n",
        "*   **Accuracy**: `0.9974`\n",
        "*   **Best Parameters**: `{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}`\n",
        "*   **Class 0 (Majority)**: Precision: `1.00`, Recall: `1.00`, F1-score: `1.00`\n",
        "*   **Class 1 (Minority)**: Precision: `0.98`, Recall: `0.98`, F1-score: `0.98`\n",
        "\n",
        "**Observations and Comparison:**\n",
        "\n",
        "The Grid Search identified `n_estimators=200`, `max_depth=None` (unlimited), and `min_samples_leaf=1` as the best parameters. The initial RandomForest model was created with `n_estimators=100`, `max_depth=None` (default), and `min_samples_leaf=1` (default).\n",
        "\n",
        "*   **Accuracy**: The accuracy improved slightly from `0.9973` to `0.9974`. While this is a marginal increase, it indicates that tuning the number of estimators (from 100 to 200) had a positive, albeit small, impact.\n",
        "*   **Precision, Recall, F1-score**: For both classes (0 and 1), the precision, recall, and f1-scores remained excellent and largely unchanged. The model was already performing very well on both classes even before hyperparameter tuning.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The Random Forest model, even with its initial default parameters (or slight tuning), demonstrates very strong performance on this dataset. The Grid Search confirmed that increasing `n_estimators` slightly improved the overall accuracy, but the model was already highly effective. This suggests that the dataset is well-suited for a powerful ensemble method like Random Forest, and further complex tuning might yield diminishing returns given the already near-perfect scores."
      ],
      "id": "7e1996f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "666800f6"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the Grid Search and Ensemble Learning results, including the best hyperparameters found, the performance of the optimized ensemble model, and a comparison with previous baseline models.\n"
      ],
      "id": "666800f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80fc517"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The comprehensive summary of the Grid Search and Ensemble Learning results is provided in the \"Data Analysis Key Findings\" section below.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Baseline Ensemble Model Performance**: The initial RandomForestClassifier, with `n_estimators=100`, achieved an accuracy of `0.9973` on the test set. Its classification report showed near-perfect scores for both classes (Class 0: Precision, Recall, F1-score all `1.00`; Class 1: Precision, Recall, F1-score all `0.98`).\n",
        "*   **Hyperparameter Grid for Grid Search**: A parameter grid was defined for tuning the RandomForestClassifier, including `n_estimators` (`[50, 100, 200]`), `max_depth` (`[10, 20, None]`), and `min_samples_leaf` (`[1, 5, 10]`).\n",
        "*   **Best Hyperparameters from Grid Search**: The GridSearchCV identified the best hyperparameters as `{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 200}`. The best cross-validation accuracy obtained during the search was `0.9970`.\n",
        "*   **Optimized Ensemble Model Performance**: The RandomForestClassifier with the best hyperparameters (`n_estimators=200`, `max_depth=None`, `min_samples_leaf=1`) achieved an accuracy of `0.9974` on the test set. Its classification report maintained excellent performance (Class 0: Precision, Recall, F1-score all `1.00`; Class 1: Precision, Recall, F1-score all `0.98`).\n",
        "*   **Comparison with Baseline Models**: The optimized ensemble model showed a marginal increase in accuracy from `0.9973` (baseline) to `0.9974`. While the overall metrics (precision, recall, F1-score) remained largely unchanged and exceptionally high for both classes, the Grid Search confirmed that increasing `n_estimators` from 100 to 200 provided a slight performance boost.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The RandomForest model already demonstrated extremely high performance even with its initial default parameters, suggesting the dataset is highly amenable to this type of ensemble method. Further extensive hyperparameter tuning may yield only marginal gains.\n",
        "*   Given the near-perfect scores, a next step could involve exploring more challenging datasets or introducing more complex feature engineering to identify if the model's robustness holds up under different conditions, or to confirm if the current dataset is relatively easy to classify.\n"
      ],
      "id": "e80fc517"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}