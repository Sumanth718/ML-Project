{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef277e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eef277e5",
        "outputId": "1483e8e4-ad1a-4654-d1aa-e30fb045aebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Outputs will be saved to: /content/drive/MyDrive/Lab6_results\n",
            "Graphviz installed\n",
            "Successfully loaded /content/drive/MyDrive/UNSW.csv.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Comprehensive Program Execution (Consolidated for Robustness)\n",
        "\n",
        "# --- 1. Core Imports and Setup ---\n",
        "from google.colab import drive\n",
        "import os, time, joblib, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Mount Google Drive and setup output directory\n",
        "drive.mount('/content/drive')\n",
        "OUT_DIR = '/content/drive/MyDrive/Lab6_results'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print('Outputs will be saved to:', OUT_DIR)\n",
        "\n",
        "# Install graphviz (optional, for rendering .dot -> .png)\n",
        "!apt-get -qq install -y graphviz\n",
        "!pip -q install graphviz\n",
        "print('Graphviz installed')\n",
        "\n",
        "# Define cv for all GridSearch operations\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Helper functions\n",
        "def measure_inference_time(model, X_sample, repeats=30):\n",
        "    start = time.time()\n",
        "    for _ in range(repeats):\n",
        "        model.predict(X_sample)\n",
        "    return (time.time() - start) / repeats\n",
        "\n",
        "def plot_confusion(y_true, y_pred, title, out_path=None):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(4,3))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "\n",
        "    # Ensure target_names is available, otherwise use generic labels\n",
        "    if 'target_names' in globals() and len(target_names) == cm.shape[0]:\n",
        "        plt.xticks(np.arange(len(target_names)), target_names, rotation=45, ha='right')\n",
        "        plt.yticks(np.arange(len(target_names)), target_names)\n",
        "    else:\n",
        "        plt.xticks(np.arange(cm.shape[0]))\n",
        "        plt.yticks(np.arange(cm.shape[0]))\n",
        "    plt.colorbar()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, cm[i,j], ha='center', va='center')\n",
        "    plt.tight_layout()\n",
        "    if out_path:\n",
        "        plt.savefig(out_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- 2. Data Loading and Preprocessing ---\n",
        "file_path = '/content/drive/MyDrive/UNSW.csv.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    print(f\"Successfully loaded {file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {file_path} was not found. Please ensure it exists in your Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "\n",
        "# Convert columns to numeric, coercing errors, then impute missing values with their mean\n",
        "df['0.4'] = pd.to_numeric(df['0.4'], errors='coerce')\n",
        "mean_0_4 = df['0.4'].mean()\n",
        "df['0.4'] = df['0.4'].fillna(mean_0_4)\n",
        "\n",
        "df['0.5'] = pd.to_numeric(df['0.5'], errors='coerce')\n",
        "mean_0_5 = df['0.5'].mean()\n",
        "df['0.5'] = df['0.5'].fillna(mean_0_5)\n",
        "\n",
        "df['Unnamed: 47'] = pd.to_numeric(df['Unnamed: 47'], errors='coerce')\n",
        "mean_unnamed_47 = df['Unnamed: 47'].mean()\n",
        "df['Unnamed: 47'] = df['Unnamed: 47'].fillna(mean_unnamed_47)\n",
        "\n",
        "# Drop 'Unnamed: 47' column as intended\n",
        "df.drop(columns=['Unnamed: 47'], inplace=True)\n",
        "\n",
        "# Define y and X\n",
        "y = df['0.7']\n",
        "X = df.drop('0.7', axis=1)\n",
        "\n",
        "# Identify categorical and numeric features\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "# Process '0.6' column (convert to numeric and impute) and update feature lists\n",
        "X['0.6'] = pd.to_numeric(X['0.6'], errors='coerce')\n",
        "mean_0_6 = X['0.6'].mean()\n",
        "X['0.6'] = X['0.6'].fillna(mean_0_6)\n",
        "\n",
        "if '0.6' in categorical_features:\n",
        "    categorical_features.remove('0.6')\n",
        "if '0.6' not in numeric_features:\n",
        "    numeric_features.append('0.6')\n",
        "\n",
        "# Perform one-hot encoding\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "print(f\"Original features shape: {X.shape}\")\n",
        "print(f\"Encoded features shape: {X_encoded.shape}\")\n",
        "\n",
        "# Define feature_names and target_names for UNSW dataset\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "if sorted(y.unique().tolist()) == [0, 1]:\n",
        "    target_names = ['Normal', 'Attack']\n",
        "else:\n",
        "    target_names = [str(x) for x in sorted(y.unique().tolist())]\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Testing features shape: {X_test.shape}\")\n",
        "print(f\"Training target shape: {y_train.shape}\")\n",
        "print(f\"Testing target shape: {y_test.shape}\")\n",
        "print(f\"Unique values in target variable y: {y.unique()}\")\n",
        "\n",
        "\n",
        "# --- 3. Model Training and Evaluation ---\n",
        "\n",
        "# Decision Tree GridSearch\n",
        "dt_base = DecisionTreeClassifier(random_state=42)\n",
        "param_grid_dt = {\n",
        "    'criterion': ['gini','entropy'],\n",
        "    'max_depth': [3,5,8, None],\n",
        "    'min_samples_split': [2,5,10],\n",
        "    'min_samples_leaf': [1,2,4]\n",
        "}\n",
        "grid_dt = GridSearchCV(dt_base, param_grid_dt, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting Decision Tree GridSearch (this may take a while)...\")\n",
        "t0 = time.time()\n",
        "grid_dt.fit(X_train, y_train)\n",
        "print(\"DT GridSearch time (s):\", time.time()-t0)\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "print(\"Best DT params:\", grid_dt.best_params_, \"Best CV F1:\", grid_dt.best_score_)\n",
        "\n",
        "# Evaluate and save DT\n",
        "y_pred_dt = best_dt.predict(X_test)\n",
        "print(\"DT Test acc:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"DT Test F1:\", f1_score(y_test, y_pred_dt))\n",
        "print(classification_report(y_test, y_pred_dt, target_names=target_names))\n",
        "joblib.dump(best_dt, os.path.join(OUT_DIR, 'best_decision_tree.joblib'))\n",
        "dot_path = os.path.join(OUT_DIR, 'Best_DecisionTree.dot')\n",
        "export_graphviz(best_dt, out_file=dot_path, feature_names=list(feature_names), class_names=list(target_names), rounded=True, filled=True)\n",
        "png_path = os.path.join(OUT_DIR, 'Best_DecisionTree.png')\n",
        "!dot -Tpng \"{dot_path}\" -o \"{png_path}\" || true\n",
        "print(\"Saved .dot and attempted to render png at:\", png_path)\n",
        "plt.figure(figsize=(12,6))\n",
        "plot_tree(best_dt, feature_names=feature_names, class_names=target_names, filled=True, rounded=True)\n",
        "plt.title('Best Decision Tree')\n",
        "plt.show()\n",
        "\n",
        "# SVC GridSearch (Pipeline with StandardScaler)\n",
        "pipe_svc = Pipeline([('scaler', StandardScaler()), ('svc', SVC(probability=True, random_state=42))])\n",
        "param_grid_svc = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__kernel': ['linear', 'rbf'],\n",
        "    'svc__gamma': ['scale', 'auto']\n",
        "}\n",
        "grid_svc = GridSearchCV(pipe_svc, param_grid_svc, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting SVC GridSearch...\")\n",
        "t0 = time.time()\n",
        "grid_svc.fit(X_train, y_train)\n",
        "print(\"SVC GridSearch time (s):\", time.time()-t0)\n",
        "\n",
        "best_svc = grid_svc.best_estimator_\n",
        "print(\"Best SVC params:\", grid_svc.best_params_, \"Best CV F1:\", grid_svc.best_score_)\n",
        "\n",
        "# Evaluate and save SVC\n",
        "y_pred_svc = best_svc.predict(X_test)\n",
        "print(\"SVC Test acc:\", accuracy_score(y_test, y_pred_svc))\n",
        "print(\"SVC Test F1:\", f1_score(y_test, y_pred_svc))\n",
        "print(classification_report(y_test, y_pred_svc, target_names=target_names))\n",
        "joblib.dump(best_svc, os.path.join(OUT_DIR, 'best_svc.joblib'))\n",
        "\n",
        "# Bagging (SVC & DT) + Voting ensemble\n",
        "\n",
        "# Bagging SVC (tune bagging params)\n",
        "bag_svc = BaggingClassifier(estimator=best_svc, random_state=42)\n",
        "param_grid_bag_svc = {'n_estimators': [10, 25, 50], 'max_samples': [0.6, 0.8, 1.0]}\n",
        "grid_bag_svc = GridSearchCV(bag_svc, param_grid_bag_svc, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting Bagging SVC GridSearch...\")\n",
        "t0 = time.time()\n",
        "grid_bag_svc.fit(X_train, y_train)\n",
        "print(\"Bagging SVC time (s):\", time.time()-t0)\n",
        "best_bag_svc = grid_bag_svc.best_estimator_\n",
        "print(\"Best Bagging SVC:\", grid_bag_svc.best_params_, \"CV F1:\", grid_bag_svc.best_score_)\n",
        "joblib.dump(best_bag_svc, os.path.join(OUT_DIR, 'best_bag_svc.joblib'))\n",
        "\n",
        "# Bagging DecisionTree\n",
        "base_dt_bag = DecisionTreeClassifier(random_state=42) # Renamed to avoid conflict if best_dt is used directly\n",
        "bag_dt = BaggingClassifier(estimator=base_dt_bag, random_state=42)\n",
        "param_grid_bag_dt = {\n",
        "    'n_estimators': [10, 25, 50],\n",
        "    'max_samples': [0.6, 0.8, 1.0],\n",
        "    'estimator__max_depth': [3,5,8],\n",
        "    'estimator__min_samples_leaf': [1,2,4]\n",
        "}\n",
        "grid_bag_dt = GridSearchCV(bag_dt, param_grid_bag_dt, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting Bagging DT GridSearch...\")\n",
        "t0 = time.time()\n",
        "grid_bag_dt.fit(X_train, y_train)\n",
        "print(\"Bagging DT time (s):\", time.time()-t0)\n",
        "best_bag_dt = grid_bag_dt.best_estimator_\n",
        "print(\"Best Bagging DT:\", grid_bag_dt.best_params_, \"CV F1:\", grid_bag_dt.best_score_)\n",
        "joblib.dump(best_bag_dt, os.path.join(OUT_DIR, 'best_bag_dt.joblib'))\n",
        "\n",
        "# Voting ensemble (soft)\n",
        "voting = VotingClassifier(estimators=[('bag_svc', best_bag_svc), ('bag_dt', best_bag_dt)], voting='soft')\n",
        "voting.fit(X_train, y_train)\n",
        "joblib.dump(voting, os.path.join(OUT_DIR, 'voting_ensemble.joblib'))\n",
        "\n",
        "# Evaluate and save summary\n",
        "models = {'DecisionTree': best_dt, 'SVC': best_svc, 'Bagging_SVC': best_bag_svc, 'Bagging_DT': best_bag_dt, 'Voting': voting}\n",
        "rows = []\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    rows.append({'model': name, 'accuracy': accuracy_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), 'recall': recall_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred), 'inf_time_s': measure_inference_time(model, X_test, repeats=30)})\n",
        "results = pd.DataFrame(rows).set_index('model')\n",
        "print(\"\\n--- Model Performance Summary ---\")\n",
        "print(results)\n",
        "results.to_csv(os.path.join(OUT_DIR, 'lab6_results_summary.csv'))\n",
        "\n",
        "# Save confusion matrices and accuracy bar\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    plot_confusion(y_test, y_pred, f'Confusion: {name}', out_path=os.path.join(OUT_DIR, f'confusion_{name}.png'))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(results.index, results['accuracy'])\n",
        "plt.title('Test set accuracy by model'); plt.ylabel('Accuracy'); plt.ylim(0.8,1.0)\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, 'accuracy_bar.png'))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 4. Save Run Notes ---\n",
        "with open(os.path.join(OUT_DIR, 'lab6_run_notes.txt'), 'w') as f:\n",
        "    f.write('LAB6 Colab run — GridSearch and Ensemble learning. Check saved models and figures in this folder.\\n')\n",
        "print(\"\\nSaved run notes to\", os.path.join(OUT_DIR, 'lab6_run_notes.txt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d64588c3"
      },
      "source": [
        "# Task\n",
        "Execute the consolidated program in Cell 1 to perform data loading, preprocessing, model training, and evaluation for the `UNSW.csv.csv` dataset, then summarize the performance of all trained models and confirm that all outputs (models, plots, and a summary CSV) have been saved to the `/content/drive/MyDrive/Lab6_results` directory."
      ],
      "id": "d64588c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4449d3f3"
      },
      "source": [
        "## Execute Consolidated Program\n",
        "\n",
        "### Subtask:\n",
        "Execute the comprehensive code in Cell 1 to perform data loading, preprocessing, model training, evaluation, and saving of results for the `UNSW.csv.csv` dataset.\n"
      ],
      "id": "4449d3f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81e94c43"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to execute the comprehensive code in Cell 1. I will use the `code_block` command to run the content of `cell_id: eef277e5`.\n",
        "\n"
      ],
      "id": "81e94c43"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4b481795",
        "outputId": "67857a09-52c6-4c1f-9606-443bf8973e2b"
      },
      "source": [
        "# Cell 1: Comprehensive Program Execution (Consolidated for Robustness)\n",
        "\n",
        "# --- 1. Core Imports and Setup ---\n",
        "from google.colab import drive\n",
        "import os, time, joblib, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Mount Google Drive and setup output directory\n",
        "drive.mount('/content/drive')\n",
        "OUT_DIR = '/content/drive/MyDrive/Lab6_results'\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print('Outputs will be saved to:', OUT_DIR)\n",
        "\n",
        "# Install graphviz (optional, for rendering .dot -> .png)\n",
        "!apt-get -qq install -y graphviz\n",
        "!pip -q install graphviz\n",
        "print('Graphviz installed')\n",
        "\n",
        "# Define cv for all GridSearch operations\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Helper functions\n",
        "def measure_inference_time(model, X_sample, repeats=30):\n",
        "    start = time.time()\n",
        "    for _ in range(repeats):\n",
        "        model.predict(X_sample)\n",
        "    return (time.time() - start) / repeats\n",
        "\n",
        "def plot_confusion(y_true, y_pred, title, out_path=None):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(4,3))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "\n",
        "    # Ensure target_names is available, otherwise use generic labels\n",
        "    if 'target_names' in globals() and len(target_names) == cm.shape[0]:\n",
        "        plt.xticks(np.arange(len(target_names)), target_names, rotation=45, ha='right')\n",
        "        plt.yticks(np.arange(len(target_names)), target_names)\n",
        "    else:\n",
        "        plt.xticks(np.arange(cm.shape[0]))\n",
        "        plt.yticks(np.arange(cm.shape[0]))\n",
        "    plt.colorbar()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, cm[i,j], ha='center', va='center')\n",
        "    plt.tight_layout()\n",
        "    if out_path:\n",
        "        plt.savefig(out_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- 2. Data Loading and Preprocessing ---\n",
        "file_path = '/content/drive/MyDrive/UNSW.csv.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    print(f\"Successfully loaded {file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {file_path} was not found. Please ensure it exists in your Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "\n",
        "# Convert columns to numeric, coercing errors, then impute missing values with their mean\n",
        "df['0.4'] = pd.to_numeric(df['0.4'], errors='coerce')\n",
        "mean_0_4 = df['0.4'].mean()\n",
        "df['0.4'] = df['0.4'].fillna(mean_0_4)\n",
        "\n",
        "df['0.5'] = pd.to_numeric(df['0.5'], errors='coerce')\n",
        "mean_0_5 = df['0.5'].mean()\n",
        "df['0.5'] = df['0.5'].fillna(mean_0_5)\n",
        "\n",
        "df['Unnamed: 47'] = pd.to_numeric(df['Unnamed: 47'], errors='coerce')\n",
        "mean_unnamed_47 = df['Unnamed: 47'].mean()\n",
        "df['Unnamed: 47'] = df['Unnamed: 47'].fillna(mean_unnamed_47)\n",
        "\n",
        "# Drop 'Unnamed: 47' column as intended\n",
        "df.drop(columns=['Unnamed: 47'], inplace=True)\n",
        "\n",
        "# Define y and X\n",
        "y = df['0.7']\n",
        "X = df.drop('0.7', axis=1)\n",
        "\n",
        "# Identify categorical and numeric features\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numeric_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "# Process '0.6' column (convert to numeric and impute) and update feature lists\n",
        "X['0.6'] = pd.to_numeric(X['0.6'], errors='coerce')\n",
        "mean_0_6 = X['0.6'].mean()\n",
        "X['0.6'] = X['0.6'].fillna(mean_0_6)\n",
        "\n",
        "if '0.6' in categorical_features:\n",
        "    categorical_features.remove('0.6')\n",
        "if '0.6' not in numeric_features:\n",
        "    numeric_features.append('0.6')\n",
        "\n",
        "# Perform one-hot encoding\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "print(f\"Original features shape: {X.shape}\")\n",
        "print(f\"Encoded features shape: {X_encoded.shape}\")\n",
        "\n",
        "# Define feature_names and target_names for UNSW dataset\n",
        "feature_names = X_encoded.columns.tolist()\n",
        "if sorted(y.unique().tolist()) == [0, 1]:\n",
        "    target_names = ['Normal', 'Attack']\n",
        "else:\n",
        "    target_names = [str(x) for x in sorted(y.unique().tolist())]\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Testing features shape: {X_test.shape}\")\n",
        "print(f\"Training target shape: {y_train.shape}\")\n",
        "print(f\"Testing target shape: {y_test.shape}\")\n",
        "print(f\"Unique values in target variable y: {y.unique()}\")\n",
        "\n",
        "\n",
        "# --- 3. Model Training and Evaluation ---\n",
        "\n",
        "# Decision Tree GridSearch\n",
        "dt_base = DecisionTreeClassifier(random_state=42)\n",
        "param_grid_dt = {\n",
        "    'criterion': ['gini','entropy'],\n",
        "    'max_depth': [3,5,8, None],\n",
        "    'min_samples_split': [2,5,10],\n",
        "    'min_samples_leaf': [1,2,4]\n",
        "}\n",
        "grid_dt = GridSearchCV(dt_base, param_grid_dt, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting Decision Tree GridSearch (this may take a while)...\")\n",
        "t0 = time.time()\n",
        "grid_dt.fit(X_train, y_train)\n",
        "print(\"DT GridSearch time (s):\", time.time()-t0)\n",
        "\n",
        "best_dt = grid_dt.best_estimator_\n",
        "print(\"Best DT params:\", grid_dt.best_params_, \"Best CV F1:\", grid_dt.best_score_)\n",
        "\n",
        "# Evaluate and save DT\n",
        "y_pred_dt = best_dt.predict(X_test)\n",
        "print(\"DT Test acc:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"DT Test F1:\", f1_score(y_test, y_pred_dt))\n",
        "print(classification_report(y_test, y_pred_dt, target_names=target_names))\n",
        "joblib.dump(best_dt, os.path.join(OUT_DIR, 'best_decision_tree.joblib'))\n",
        "dot_path = os.path.join(OUT_DIR, 'Best_DecisionTree.dot')\n",
        "export_graphviz(best_dt, out_file=dot_path, feature_names=list(feature_names), class_names=list(target_names), rounded=True, filled=True)\n",
        "png_path = os.path.join(OUT_DIR, 'Best_DecisionTree.png')\n",
        "!dot -Tpng \"{dot_path}\" -o \"{png_path}\" || true\n",
        "print(\"Saved .dot and attempted to render png at:\", png_path)\n",
        "plt.figure(figsize=(12,6))\n",
        "plot_tree(best_dt, feature_names=feature_names, class_names=target_names, filled=True, rounded=True)\n",
        "plt.title('Best Decision Tree')\n",
        "plt.show()\n",
        "\n",
        "# SVC GridSearch (Pipeline with StandardScaler)\n",
        "pipe_svc = Pipeline([('scaler', StandardScaler()), ('svc', SVC(probability=True, random_state=42))])\n",
        "param_grid_svc = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__kernel': ['linear', 'rbf'],\n",
        "    'svc__gamma': ['scale', 'auto']\n",
        "}\n",
        "grid_svc = GridSearchCV(pipe_svc, param_grid_svc, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting SVC GridSearch...\")\n",
        "t0 = time.time()\n",
        "grid_svc.fit(X_train, y_train)\n",
        "print(\"SVC GridSearch time (s):\", time.time()-t0)\n",
        "\n",
        "best_svc = grid_svc.best_estimator_\n",
        "print(\"Best SVC params:\", grid_svc.best_params_, \"Best CV F1:\", grid_svc.best_score_)\n",
        "\n",
        "# Evaluate and save SVC\n",
        "y_pred_svc = best_svc.predict(X_test)\n",
        "print(\"SVC Test acc:\", accuracy_score(y_test, y_pred_svc))\n",
        "print(\"SVC Test F1:\", f1_score(y_test, y_pred_svc))\n",
        "print(classification_report(y_test, y_pred_svc, target_names=target_names))\n",
        "joblib.dump(best_svc, os.path.join(OUT_DIR, 'best_svc.joblib'))\n",
        "\n",
        "# Bagging (SVC & DT) + Voting ensemble\n",
        "\n",
        "# Bagging SVC (tune bagging params)\n",
        "bag_svc = BaggingClassifier(estimator=best_svc, random_state=42)\n",
        "param_grid_bag_svc = {'n_estimators': [10, 25, 50], 'max_samples': [0.6, 0.8, 1.0]}\n",
        "grid_bag_svc = GridSearchCV(bag_svc, param_grid_bag_svc, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting Bagging SVC GridSearch...\")\n",
        "t0 = time.time()\n",
        "grid_bag_svc.fit(X_train, y_train)\n",
        "print(\"Bagging SVC time (s):\", time.time()-t0)\n",
        "best_bag_svc = grid_bag_svc.best_estimator_\n",
        "print(\"Best Bagging SVC:\", grid_bag_svc.best_params_, \"CV F1:\", grid_bag_svc.best_score_)\n",
        "joblib.dump(best_bag_svc, os.path.join(OUT_DIR, 'best_bag_svc.joblib'))\n",
        "\n",
        "# Bagging DecisionTree\n",
        "base_dt_bag = DecisionTreeClassifier(random_state=42) # Renamed to avoid conflict if best_dt is used directly\n",
        "bag_dt = BaggingClassifier(estimator=base_dt_bag, random_state=42)\n",
        "param_grid_bag_dt = {\n",
        "    'n_estimators': [10, 25, 50],\n",
        "    'max_samples': [0.6, 0.8, 1.0],\n",
        "    'estimator__max_depth': [3,5,8],\n",
        "    'estimator__min_samples_leaf': [1,2,4]\n",
        "}\n",
        "grid_bag_dt = GridSearchCV(bag_dt, param_grid_bag_dt, cv=cv, scoring='f1', n_jobs=-1, verbose=1, refit=True)\n",
        "print(\"\\nFitting Bagging DT GridSearch...\")\n",
        "t0 = time.time()\n",
        "grid_bag_dt.fit(X_train, y_train)\n",
        "print(\"Bagging DT time (s):\", time.time()-t0)\n",
        "best_bag_dt = grid_bag_dt.best_estimator_\n",
        "print(\"Best Bagging DT:\", grid_bag_dt.best_params_, \"CV F1:\", grid_bag_dt.best_score_)\n",
        "joblib.dump(best_bag_dt, os.path.join(OUT_DIR, 'best_bag_dt.joblib'))\n",
        "\n",
        "# Voting ensemble (soft)\n",
        "voting = VotingClassifier(estimators=[('bag_svc', best_bag_svc), ('bag_dt', best_bag_dt)], voting='soft')\n",
        "voting.fit(X_train, y_train)\n",
        "joblib.dump(voting, os.path.join(OUT_DIR, 'voting_ensemble.joblib'))\n",
        "\n",
        "# Evaluate and save summary\n",
        "models = {'DecisionTree': best_dt, 'SVC': best_svc, 'Bagging_SVC': best_bag_svc, 'Bagging_DT': best_bag_dt, 'Voting': voting}\n",
        "rows = []\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    rows.append({'model': name, 'accuracy': accuracy_score(y_test, y_pred), 'precision': precision_score(y_test, y_pred), 'recall': recall_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred), 'inf_time_s': measure_inference_time(model, X_test, repeats=30)})\n",
        "results = pd.DataFrame(rows).set_index('model')\n",
        "print(\"\\n--- Model Performance Summary ---\")\n",
        "print(results)\n",
        "results.to_csv(os.path.join(OUT_DIR, 'lab6_results_summary.csv'))\n",
        "\n",
        "# Save confusion matrices and accuracy bar\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    plot_confusion(y_test, y_pred, f'Confusion: {name}', out_path=os.path.join(OUT_DIR, f'confusion_{name}.png'))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(results.index, results['accuracy'])\n",
        "plt.title('Test set accuracy by model'); plt.ylabel('Accuracy'); plt.ylim(0.8,1.0)\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, 'accuracy_bar.png'))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 4. Save Run Notes ---\n",
        "with open(os.path.join(OUT_DIR, 'lab6_run_notes.txt'), 'w') as f:\n",
        "    f.write('LAB6 Colab run — GridSearch and Ensemble learning. Check saved models and figures in this folder.\\n')\n",
        "print(\"\\nSaved run notes to\", os.path.join(OUT_DIR, 'lab6_run_notes.txt'))"
      ],
      "id": "4b481795",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Outputs will be saved to: /content/drive/MyDrive/Lab6_results\n",
            "Graphviz installed\n",
            "Successfully loaded /content/drive/MyDrive/UNSW.csv.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Wtm2sLw3fMxj",
        "outputId": "02999fd6-eae1-45f8-ab2f-6dce73720aad"
      },
      "id": "Wtm2sLw3fMxj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b256cf07"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the performance of all trained models and confirm that all outputs (models, plots, and a summary CSV) have been saved to the designated output directory in Google Drive.\n"
      ],
      "id": "b256cf07"
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}